{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3cd8c50-99f0-4d22-b6d2-937792adb2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input layer - CNN / Dense Layer/ Convoluted Layer \n",
    "# i. ReLU layer\n",
    "# ii. Pooling layer\n",
    "#   i. batch Normalization\n",
    "#   ii. Dropout layer\n",
    "#   iii. Upsampling\n",
    "\n",
    "# 2. Hidden layer - NN\n",
    "# 3. Output layer - FCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a054130c-1f2b-4351-97b4-348a14d8ae8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Tensor Flow\n",
    "# 2. Pytorch\n",
    "# 3. MaxNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53f701a7-11e7-40fa-9ffb-0dac6eb1de7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\e.haque\\anaconda3\\lib\\site-packages (2.10.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\e.haque\\anaconda3\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\e.haque\\anaconda3\\lib\\site-packages (from tensorflow) (3.19.1)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\e.haque\\anaconda3\\lib\\site-packages (from tensorflow) (3.6.0)\n",
      "Requirement already satisfied: keras<2.11,>=2.10.0 in c:\\users\\e.haque\\anaconda3\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\e.haque\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\e.haque\\anaconda3\\lib\\site-packages (from tensorflow) (0.27.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\e.haque\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\e.haque\\anaconda3\\lib\\site-packages (from tensorflow) (4.1.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\e.haque\\anaconda3\\lib\\site-packages (from tensorflow) (21.3)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\e.haque\\anaconda3\\lib\\site-packages (from tensorflow) (1.21.5)\n",
      "Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in c:\\users\\e.haque\\anaconda3\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\e.haque\\anaconda3\\lib\\site-packages (from tensorflow) (61.2.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\e.haque\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\e.haque\\anaconda3\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\e.haque\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\e.haque\\anaconda3\\lib\\site-packages (from tensorflow) (14.0.6)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\e.haque\\anaconda3\\lib\\site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: tensorboard<2.11,>=2.10 in c:\\users\\e.haque\\anaconda3\\lib\\site-packages (from tensorflow) (2.10.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\e.haque\\anaconda3\\lib\\site-packages (from tensorflow) (1.3.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\e.haque\\anaconda3\\lib\\site-packages (from tensorflow) (22.10.26)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\e.haque\\anaconda3\\lib\\site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\e.haque\\anaconda3\\lib\\site-packages (from tensorflow) (1.42.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\e.haque\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\e.haque\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\e.haque\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\e.haque\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (1.33.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\e.haque\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\e.haque\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\e.haque\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\e.haque\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.27.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\e.haque\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\e.haque\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (4.2.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\e.haque\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\e.haque\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\e.haque\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\e.haque\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\e.haque\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\e.haque\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\e.haque\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (3.3)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\e.haque\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (3.2.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\e.haque\\anaconda3\\lib\\site-packages (from packaging->tensorflow) (3.0.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d76f5b67-e1c6-41b3-b337-632d1e03fb20",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'warning' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 12>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m \u001b[43mwarning\u001b[49m\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     13\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatplotlib\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minline\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'warning' is not defined"
     ]
    }
   ],
   "source": [
    "# this sectionm is for model\n",
    "import tensorflow as tf\n",
    "\n",
    "# this section for algebraic analysis\n",
    "import numpy as np\n",
    "\n",
    "# This section for vizualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import warnings\n",
    "warning.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7176b105-3a76-42cd-8e19-c667dee8b0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    \n",
    "    def _init_(self,layers):\n",
    "          self.layers=layers\n",
    "          self.L=len(layers)  \n",
    "            \n",
    "          self.number_feature=layers[0]\n",
    "          self.number_class=layers[-1]\n",
    "          \n",
    "        # creating weight an dbias\n",
    "          self.W={}\n",
    "          self.b={}\n",
    "    \n",
    "          self.dw={}\n",
    "          self.db={}\n",
    "    \n",
    "          self.setup()\n",
    "          \n",
    "    def setup(self):\n",
    "        for i in range(1,self.L):\n",
    "            self.W[i]=tf.Variable(tf.random.normal(shape=(self.layers[i],self.layers[i-1])))\n",
    "            self.b[i]=tf.Variable(tf.random.normal(shape=(self.layers[i],1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aab42c8-ce0a-4de5-878a-884232b7f3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. dtype=\"float32\"\n",
    "# 2. dtype=np.float32\n",
    "# 3. dtype=tf.float32\n",
    "# 4. dtype=torch.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91a30b30-f0e0-451b-ab21-abb5fc005037",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(NeuralNetwork):\n",
    "    \n",
    "    def forwardpass(self,A):\n",
    "        A=tf.convert_to_tensor(A,dtype=float32)\n",
    "        for i in range(1,self.L):\n",
    "            Z=tf.matmul(A,tf.transpose(self.W[i]))+tf.transpose(self.b[i]) \n",
    "            if i!=self.L-1:\n",
    "                A=tf.nn.relu(Z)\n",
    "            else:\n",
    "                A=Z\n",
    "        return A            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9a29c8d-d644-446a-b39e-074d853233ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will us ethis section for computing loss function and Upgrading the previous parameters\n",
    "class NeuralNetwork(NeuralNetwork):\n",
    "    def compute_loss(self, A,Y):  \n",
    "        return tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(Y,A))\n",
    "    \n",
    "    def upgrade_parameters():   \n",
    "      for j in range(1,self.L):\n",
    "        self.W[j].assing_sub(lr*self.dw[j])\n",
    "        self.b[j].assing_sub(lr*self.db[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6fbd928-bbba-4fbf-bb9b-7c3d06c3fef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(NeuralNetwork):\n",
    "   def predict(self,x):\n",
    "    A=self.forwardPass(x)\n",
    "    return tf.argmax(tf.nn.softmax(A),axis=1)\n",
    "\n",
    "   def info(self):\n",
    "    num_params=0\n",
    "    for i in range(1,self.L):\n",
    "        num_params+=self.W[i].shape[0]*self.W[i].shape[1]\n",
    "        num_params+=self.b[i].shape[0]\n",
    "            \n",
    "        print(\"Number of Feature:{}\".format(self.number_feature))\n",
    "        print(\"Total number of class is:{}\".format(self.number_class))\n",
    "        \n",
    "        print(\"Hidden Layer information is:{}\".format())\n",
    "        for j in range(1,self.L-1):\n",
    "            print(\"layer:{},Units {}\".format(j,self.layers[j]))\n",
    "        print(\"Total Number of parameters: {}\".format(num_params))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7dad25f-abfa-4491-b7ca-821082e8c03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training Start\n",
    "\n",
    "# class NeuralNetwork(NeuralNetwork):\n",
    "#     def train(self,x_train, y_train, x_test, y_test, epochs, step_per_epochs, batch_size,lr):\n",
    "#         history={\"val_loss\":[],\n",
    "#                  \"train_loss\":[],\n",
    "#                 \"val_acc\":[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df7b4be8-3ed5-4b84-9706-bc38b18bdcf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax([0.12,0.09])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fd80eb-453f-4978-9491-07923f4f3367",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training Start\n",
    "\n",
    "class NeuralNetwork(NeuralNetwork):\n",
    "    def train(self,x_train, y_train, x_test, y_test, epochs, step_per_epochs, batch_size,lr):\n",
    "        history={\"val_loss\":[],\n",
    "                 \"train_loss\":[],\n",
    "                \"val_acc\":[]}\n",
    "        \n",
    "        for e in range(0,epochs)\n",
    "            training_loss_epochs=0.0\n",
    "            print(\"Epochs {}\".format(e),end=\"|\")\n",
    "            for i in range(step_per_epochs):\n",
    "                x_batch=x_train[i*batch_size:(i+1)*batch_szie]\n",
    "                y_batch=y_train[i*batch_size:(i+1)*batch_szie]\n",
    "                batch_loss=self.training_loss_on_batch(x_batch,y_batch,lr)\n",
    "                epochs_loss_train+=batch_loss\n",
    "                \n",
    "                if i %int(step_per_epochs/10)==0:\n",
    "                    print(end=\".\")\n",
    "                    \n",
    "            history['train_loss'].append(epochs_loss_train/step_per_epochs) \n",
    "         \n",
    "        valA=self.forwardPass(x_test)\n",
    "        history['val_acc'].append(self.compute_loss(y_test, valA).numpy())\n",
    "        \n",
    "        valuePr=self.predict(x_test)\n",
    "        history['val_acc'].append(np.mean(np.argmax(y_test,axis=1)==valuePr.numpy()))\n",
    "        print(\"Value Accuracy\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
